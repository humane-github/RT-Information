// -*- Java -*-
/*!
 * @file  FaceDetectorImpl.java
 * @brief ${rtcParam.description}
 * @date  $Date$
 *
 * $Id$
 */

import java.io.IOException;
import java.util.Timer;
import java.util.TimerTask;

import jp.co.humane.configlib.ConfigFile;
import jp.co.humane.opencvlib.CascadeFaceDetector;
import jp.co.humane.opencvlib.MatFactory;
import jp.co.humane.opencvlib.MatFactory.MatType;
import jp.co.humane.opencvlib.OpenCVLib;
import jp.co.humane.opencvlib.exception.CascadeClassifierException;
import jp.go.aist.rtm.RTC.DataFlowComponentBase;
import jp.go.aist.rtm.RTC.Manager;
import jp.go.aist.rtm.RTC.port.InPort;
import jp.go.aist.rtm.RTC.port.OutPort;
import jp.go.aist.rtm.RTC.util.DataRef;

import org.opencv.core.Mat;
import org.opencv.imgproc.Imgproc;

import RTC.CameraImage;
import RTC.ReturnCode_t;
import RTC.Time;
import RTC.TimedBoolean;
import RTC.TimedLong;
import RTC.TimedString;

/*!
 * @class FaceDetectorImpl
 * @brief ${rtcParam.description}
 *
 */
public class FaceDetectorImpl extends DataFlowComponentBase
{
	private final static String CONFG_PATH = ".\\InfoClerk.properties";
	private final static String CONF_CASCADE_PATH1 = "CASCADE_PATH1";
	private final static String CONF_CASCADE_PATH2 = "CASCADE_PATH2";
	private final static String CONF_CASCADE_PATH3 = "CASCADE_PATH3";
	private final static String CONF_SHOW_PREVIEW_DIALOG = "SHOW_PREVIEW_DIALOG";
	private final static String CONF_CASCADE_SCALE = "CASCADE_SCALE";
	private final static String CONF_FACE_DETECT_THRESHOLD = "FACE_DETECT_THRESHOLD";
	private final static String CONF_WAIT_TIME = "FACE_DETECT_WAIT_TIME";
	private final static String CONF_RESET_TIME = "FACE_DETECT_RESET_TIME";

	//設定ファイル管理オブジェクト
	private ConfigFile m_config = null;
	//初期化に失敗した場合に真
	private boolean m_failedInitialize = false;
	//休止状態のとき真
	private boolean m_sleep = false;
	//プレビュー画面の表示を行う場合に真
	private boolean m_showPreviewDialog = false;
	//プレビュー画面オブジェクト
	private PreviewDialog m_previewDialog = null;
	//顔検出オブジェクト
	private CascadeFaceDetector m_detector = null;
	//顔の検出回数閾値
	private int m_faceDetectThreshold = 0;
	//顔検出した回数(検出閾値よりも大きくなったら検出したとみなす）
	private int m_faceDetectCount = 0;
	//顔検出処理のwait
	private int m_waitTime = 0;
	//顔検出のリセット時間
	private int m_resetTime = 0;
	private Timer m_resetTimer = null;
	
	//設定ファイルから取得した設定値を持つ変数
	private String m_cascadePath1 = "";
	private String m_cascadePath2 = "";
	private String m_cascadePath3 = "";
	private int m_scale = 0;
	
  /*!
   * @brief constructor
   * @param manager Maneger Object
   */
	public FaceDetectorImpl(Manager manager) {  
        super(manager);
        // <rtc-template block="initializer">
        m_CameraImage_val = new CameraImage(new Time(0,0), (short)0, (short)0, (short)0, "", 0.0, new byte[255]);
        m_CameraImage = new DataRef<CameraImage>(m_CameraImage_val);
        m_CameraImageIn = new InPort<CameraImage>("CameraImage", m_CameraImage);
        m_wakeup_val = new TimedBoolean(new Time(0,0),false);
        m_wakeup = new DataRef<TimedBoolean>(m_wakeup_val);
        m_wakeupIn = new InPort<TimedBoolean>("wakeup", m_wakeup);
        m_Result_val = new TimedString(new Time(0,0),"");
        m_Result = new DataRef<TimedString>(m_Result_val);
        m_ResultOut = new OutPort<TimedString>("Result", m_Result);
        m_Faces_val = new TimedLong(new Time(0,0),0);
        m_Faces = new DataRef<TimedLong>(m_Faces_val);
        m_FacesOut = new OutPort<TimedLong>("Faces", m_Faces);
        // </rtc-template>

    }

    /**
     *
     * The initialize action (on CREATED->ALIVE transition)
     * formaer rtc_init_entry() 
     *
     * @return RTC::ReturnCode_t
     * 
     * 
     */
    @Override
    protected ReturnCode_t onInitialize() {
        // Registration: InPort/OutPort/Service
        // <rtc-template block="registration">
        // Set InPort buffers
        addInPort("CameraImage", m_CameraImageIn);
        addInPort("wakeup", m_wakeupIn);
        
        // Set OutPort buffer
        addOutPort("Result", m_ResultOut);
        addOutPort("Faces", m_FacesOut);
        // </rtc-template>

        return super.onInitialize();
    }

    /***
     *
     * The finalize action (on ALIVE->END transition)
     * formaer rtc_exiting_entry()
     *
     * @return RTC::ReturnCode_t
     * 
     * 
     */
//    @Override
//    protected ReturnCode_t onFinalize() {
//        return super.onFinalize();
//    }

    /***
     *
     * The startup action when ExecutionContext startup
     * former rtc_starting_entry()
     *
     * @param ec_id target ExecutionContext Id
     *
     * @return RTC::ReturnCode_t
     * 
     * 
     */
//    @Override
//    protected ReturnCode_t onStartup(int ec_id) {
//        return super.onStartup(ec_id);
//    }

    /***
     *
     * The shutdown action when ExecutionContext stop
     * former rtc_stopping_entry()
     *
     * @param ec_id target ExecutionContext Id
     *
     * @return RTC::ReturnCode_t
     * 
     * 
     */
//    @Override
//    protected ReturnCode_t onShutdown(int ec_id) {
//        return super.onShutdown(ec_id);
//    }

    /***
     *
     * The activated action (Active state entry action)
     * former rtc_active_entry()
     *
     * @param ec_id target ExecutionContext Id
     *
     * @return RTC::ReturnCode_t
     * 
     * 
     */
    @Override
    protected ReturnCode_t onActivated(int ec_id)
    {
    	//OpenCVのDLLをロードする
    	OpenCVLib.LoadDLL();    	
    	try
    	{
        	//設定ファイルを読み込む
        	m_config = new ConfigFile();
        	m_config.load(CONFG_PATH);
        	//設定値を取得する
        	m_cascadePath1 = m_config.getString(CONF_CASCADE_PATH1);
        	m_cascadePath2 = m_config.getString(CONF_CASCADE_PATH2);
        	m_cascadePath3 = m_config.getString(CONF_CASCADE_PATH3);
        	m_scale = m_config.getInt(CONF_CASCADE_SCALE);
        	m_showPreviewDialog = (m_config.getInt(CONF_SHOW_PREVIEW_DIALOG) == 1);
    		m_faceDetectThreshold = m_config.getInt(CONF_FACE_DETECT_THRESHOLD);
    		m_waitTime = m_config.getInt(CONF_WAIT_TIME);
    		m_resetTime = m_config.getInt(CONF_RESET_TIME);
        	//顔検出オブジェクトの初期化
        	m_detector = new CascadeFaceDetector();
    		m_detector.addCascade("cascade1", m_cascadePath1);
    		m_detector.addCascade("cascade2", m_cascadePath2);
    		m_detector.addCascade("cascade3", m_cascadePath3);
    	}
    	catch( IOException ex )
    	{
    		System.out.println(ex.getMessage());
    		m_failedInitialize = true;
    		return super.onActivated(ec_id);
    	}
    	catch(CascadeClassifierException ex2)
    	{
    		System.out.println(ex2.getMessage());
    		m_failedInitialize = true;
    		return super.onActivated(ec_id);    		
    	}
    	
		if( m_showPreviewDialog )
		{
			m_previewDialog = new PreviewDialog();
			m_previewDialog.init();			
		}		
        return super.onActivated(ec_id);
    }

    /***
     *
     * The deactivated action (Active state exit action)
     * former rtc_active_exit()
     *
     * @param ec_id target ExecutionContext Id
     *
     * @return RTC::ReturnCode_t
     * 
     * 
     */
    @Override
    protected ReturnCode_t onDeactivated(int ec_id) {
    	m_sleep = false;
    	m_failedInitialize = false;
    	if( m_previewDialog != null )
    	{
    		m_previewDialog.hideDialog();
    		m_previewDialog = null;
    	}
        return super.onDeactivated(ec_id);
    }

    /***
     *
     * The execution action that is invoked periodically
     * former rtc_active_do()
     *
     * @param ec_id target ExecutionContext Id
     *
     * @return RTC::ReturnCode_t
     * 
     * 
     */
    @Override
    protected ReturnCode_t onExecute(int ec_id)
    {
    	// 初期化に失敗していたら処理しない
    	if( m_failedInitialize ){return super.onExecute(ec_id);}
    	
    	//外部からの起動命令
    	if( m_wakeupIn.isNew() )
    	{
    		m_wakeupIn.read();
    		boolean wakeup = m_wakeup.v.data;
    		if( wakeup ){m_sleep = false;}
    		else{m_sleep = true;}
    	}
    	
    	//新規画像を取得し、かつ起動状態のときのみ処理を行う
    	if( m_CameraImageIn.isNew() && !m_sleep )
    	{
    		try
    		{
        		m_CameraImageIn.read();
        		Mat cameraMat = MatFactory.create(m_CameraImage.v.width,
        											m_CameraImage.v.height,
        											m_CameraImage.v.bpp,
        											m_CameraImage.v.pixels);

        		Mat grayImg = MatFactory.create(cameraMat.width(), cameraMat.height(), MatType.MONO_8BIT);
        		Mat smallImg = MatFactory.create(cameraMat.width()/m_scale, cameraMat.height()/m_scale, MatType.MONO_8BIT);
        		Imgproc.cvtColor(cameraMat, grayImg, Imgproc.COLOR_BGR2GRAY);
        		Imgproc.resize(grayImg, smallImg, smallImg.size(),0,0,Imgproc.INTER_LINEAR);
        		
        		//顔検出開始
        		int faces = m_detector.detect(smallImg);
        		if( faces > 0 )
        		{
        			//顔検出リセットタイマーを開始する
        			if( m_faceDetectCount == 0 ){reset(true);}
        			
        			m_faceDetectCount++;
        			if( m_faceDetectCount > m_faceDetectThreshold )
        			{
            			System.out.println("** 人物を検出しました **");
            			reset(false);
            			//起動状態のときは結果を送信
        				m_faceDetectCount = 0;
            			m_sleep = false;
            			m_Faces_val.data = faces;
            			m_FacesOut.write();
        			}
        			else
        			{
            			System.out.println(String.format("人物を検出中です...[%s/%s]", m_faceDetectCount,m_faceDetectThreshold));        				
        			}
        		}
        		if(m_showPreviewDialog){m_previewDialog.showDialog(cameraMat);}
    		}
    		catch(Exception e)
    		{
    			e.printStackTrace();
    		}

    		try {
				Thread.sleep(m_waitTime);
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
    	}
        return super.onExecute(ec_id);
    }

    /**
     * 顔検出のリセット処理
     * **/
    public void reset(boolean onoff)
    {
    	if( !onoff ){m_resetTimer.cancel();}
    	else
    	{
        	try
        	{
            	TimerTask task = new TimerTask()
            	{
        			@Override
        			public void run()
        			{
        				System.out.println("** 顔検出がタイムアウトしました **");
        				m_faceDetectCount = 0;   				
        			}
        		};
        		m_resetTimer = new Timer();
        		m_resetTimer.schedule(task, m_resetTime);    		
        	}
        	catch( Exception ex )
        	{
        		ex.printStackTrace();
        	}    		
    	}
    }
    
    /***
     *
     * The aborting action when main logic error occurred.
     * former rtc_aborting_entry()
     *
     * @param ec_id target ExecutionContext Id
     *
     * @return RTC::ReturnCode_t
     * 
     * 
     */
//  @Override
//  public ReturnCode_t onAborting(int ec_id) {
//      return super.onAborting(ec_id);
//  }

    /***
     *
     * The error action in ERROR state
     * former rtc_error_do()
     *
     * @param ec_id target ExecutionContext Id
     *
     * @return RTC::ReturnCode_t
     * 
     * 
     */
//    @Override
//    public ReturnCode_t onError(int ec_id) {
//        return super.onError(ec_id);
//    }

    /***
     *
     * The reset action that is invoked resetting
     * This is same but different the former rtc_init_entry()
     *
     * @param ec_id target ExecutionContext Id
     *
     * @return RTC::ReturnCode_t
     * 
     * 
     */
//    @Override
//    protected ReturnCode_t onReset(int ec_id) {
//        return super.onReset(ec_id);
//    }

    /***
     *
     * The state update action that is invoked after onExecute() action
     * no corresponding operation exists in OpenRTm-aist-0.2.0
     *
     * @param ec_id target ExecutionContext Id
     *
     * @return RTC::ReturnCode_t
     * 
     * 
     */
//    @Override
//    protected ReturnCode_t onStateUpdate(int ec_id) {
//        return super.onStateUpdate(ec_id);
//    }

    /***
     *
     * The action that is invoked when execution context's rate is changed
     * no corresponding operation exists in OpenRTm-aist-0.2.0
     *
     * @param ec_id target ExecutionContext Id
     *
     * @return RTC::ReturnCode_t
     * 
     * 
     */
//    @Override
//    protected ReturnCode_t onRateChanged(int ec_id) {
//        return super.onRateChanged(ec_id);
//    }
//
    // DataInPort declaration
    // <rtc-template block="inport_declare">
    protected CameraImage m_CameraImage_val;
    protected DataRef<CameraImage> m_CameraImage;
    /*!
     */
    protected InPort<CameraImage> m_CameraImageIn;

    protected TimedBoolean m_wakeup_val;
    protected DataRef<TimedBoolean> m_wakeup;
    /*!
     */
    protected InPort<TimedBoolean> m_wakeupIn;

    
    // </rtc-template>

    // DataOutPort declaration
    // <rtc-template block="outport_declare">
    protected TimedString m_Result_val;
    protected DataRef<TimedString> m_Result;
    /*!
     */
    protected OutPort<TimedString> m_ResultOut;

    protected TimedLong m_Faces_val;
    protected DataRef<TimedLong> m_Faces;
    /*!
     */
    protected OutPort<TimedLong> m_FacesOut;

    
    // </rtc-template>

    // CORBA Port declaration
    // <rtc-template block="corbaport_declare">
    
    // </rtc-template>

    // Service declaration
    // <rtc-template block="service_declare">
    
    // </rtc-template>

    // Consumer declaration
    // <rtc-template block="consumer_declare">
    
    // </rtc-template>


}

